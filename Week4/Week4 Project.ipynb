{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MachineLearning - Week 4 Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"Week4 Dataset1.csv\", skiprows=[0], names=[\"X1\",\"X2\",\"y\"])\n",
    "print(df.head())\n",
    "X1=df.iloc[:,0]\n",
    "X2=df.iloc[:,1]\n",
    "X=np.column_stack((X1,X2))\n",
    "y=df.iloc[:,2]\n",
    "\n",
    "#Knowing the input data\n",
    "print(np.shape(df))\n",
    "print(min(X1), max(X1))\n",
    "print(min(X2), max(X2))\n",
    "print(min(y), max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the input datsets\n",
    "# %matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X1,X2,y, label = \"Training Data\")\n",
    "ax.set_xlabel(\"X_1\", fontweight ='bold').set_color('red')\n",
    "ax.set_ylabel(\"X_2\", fontweight ='bold').set_color('red')\n",
    "ax.set_zlabel(\"y\", fontweight ='bold').set_color('red')\n",
    "ax.legend()\n",
    "# ax.view_init(0, 90)\n",
    "ax.set_title(\"Training data\", fontweight ='bold').set_color('red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.rc('font', size =12)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.scatter(X1[y==1],X2[y==1], c='b',marker='+', label='y=1')\n",
    "plt.scatter(X1[y==-1], X2[y==-1], c='g',marker='o', label='y=-1') \n",
    "# plt.scatter(X1[y==-1],X2[y==-1],c='b',marker='o', label=r'$y_t=-1$')\n",
    "plt.ylabel('X_2', fontweight ='bold')\n",
    "plt.xlabel('X_1', fontweight ='bold')\n",
    "plt.legend()\n",
    "plt.title(\"Training Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitNaddPoly(X, y, n=5, gridRange=2):\n",
    "    ####Splitting the model into train, and test\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y) # --> Return ytrain, ytest\n",
    "\n",
    "    ####Adding extra polynomial features equal to all combinations of powers of the two features up to power n\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    Xtrain_poly = PolynomialFeatures(n).fit_transform(Xtrain) # --> Return Xtrain_poly\n",
    "    Xtest_poly = PolynomialFeatures(n).fit_transform(Xtest) # --> Return Xtest_poly\n",
    "    X_poly = PolynomialFeatures(n).fit_transform(X)\n",
    "\n",
    "    ####Grid of feature values, to use for predictions\n",
    "    # Xt=[]\n",
    "    # grid=np.linspace(-gridRange,gridRange)\n",
    "    # for i in grid:\n",
    "    #     for j in grid:\n",
    "    #         Xt.append([i,j])\n",
    "    # Xt = np.array(Xt) #### Return Xt\n",
    "    # Xtest = PolynomialFeatures(n).fit_transform(Xt) #### Return Xtest\n",
    "    \n",
    "    return Xtrain_poly, Xtest_poly, ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(Xtrain_poly, Xtest_poly, ytrain, ytest, c):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(penalty='l2', C= c,max_iter=10000).fit(Xtrain_poly, ytrain)\n",
    "    prediction = model.predict(Xtest_poly)\n",
    "    return model, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelResults(testY,model, prediction,c):\n",
    "    print(\"C = \", c)\n",
    "    print(f\"Model Intercept = {model.intercept_}\")\n",
    "    print(f\"Model Coefficient = {model.coef_.tolist()}\")\n",
    "    from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    # print(scores)\n",
    "    print(\"Accuracy (for 5 fold cross validation): %0.2f (+/âˆ’ %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(testY,prediction))\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(testY,prediction))\n",
    "\n",
    "    # print(\"Mean square error =\", mean_squared_error(testY,prediction))\n",
    "\n",
    "    # Xt=[]\n",
    "    # grid=np.linspace(-2,2)\n",
    "    # for i in grid:\n",
    "    #     for j in grid:\n",
    "    #         Xt.append([i,j])\n",
    "    # Xt = np.array(Xt)\n",
    "\n",
    "\n",
    "    # %matplotlib widget\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # from mpl_toolkits.mplot3d import Axes3D\n",
    "    # fig = plt.figure()\n",
    "    # ax = fig.add_subplot(111, projection='3d')\n",
    "    # ax.scatter(X1,X2,y, label = \"Training Data\")\n",
    "    # ax.plot_trisurf(Xtest_poly[:,1], Xtest_poly[:,2], prediction)\n",
    "    # ax.set_xlabel(\"X_1\", fontweight ='bold').set_color('red')\n",
    "    # ax.set_ylabel(\"X_2\", fontweight ='bold').set_color('red')\n",
    "    # ax.set_zlabel(\"y\", fontweight ='bold').set_color('red')\n",
    "    # ax.legend(fontsize = 'medium')\n",
    "    # ax.set_title(f\"Training data and Prediction curve with penality C = {c}\", fontweight ='bold').set_color('red')\n",
    "    # plt.show()\n",
    "\n",
    "    # xmin, xmax = -3, 3\n",
    "    # ymin, ymax = -3, 3\n",
    "    # xd = np.array([xmin, xmax])\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.rc('font', size =12)\n",
    "    # plt.rcParams['figure.constrained_layout.use'] = True\n",
    "    # plt.scatter(X1, y, X2, c='b',marker='o') \n",
    "    # # plt.scatter(X1[y==-1],X2[y==-1],c='b',marker='o', label=r'$y_t=-1$')\n",
    "    # ##_____\n",
    "    # ##_____\n",
    "    # # plt.plot(xd, yd, 'black', lw=2)\n",
    "    # plt.xlim(xmin, xmax)\n",
    "    # plt.ylim(ymin, ymax)\n",
    "    # plt.ylabel('X_2')\n",
    "    # plt.xlabel('X_1')\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Predicted target over training data, LR model with original features\", loc='center')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummyRegressor(Xtrain_poly, Xtest_poly, ytrain, ytest):\n",
    "    from sklearn.dummy import DummyRegressor\n",
    "    dummy = DummyRegressor(strategy='mean').fit(Xtrain_poly, ytrain)\n",
    "    ydummy = dummy.predict(Xtest_poly)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print('Mean square error (Dummy) = %f'%(mean_squared_error(ytest,ydummy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummyClassifier(Xtrain_poly, Xtest_poly, ytrain, ytest):   \n",
    "   from sklearn.dummy import DummyClassifier\n",
    "   dummy = DummyClassifier(strategy='most_frequent').fit(Xtrain_poly, ytrain)\n",
    "   ydummy = dummy.predict(Xtest_poly)\n",
    "\n",
    "   from sklearn.metrics import confusion_matrix, classification_report\n",
    "   print(\"Confusion matrix:\")\n",
    "   print(confusion_matrix(ytest, ydummy))\n",
    "   print(\"Classification report:\")\n",
    "   print(classification_report(ytest, ydummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorBar(Xtrain_poly, Xtest_poly, ytrain, ytest):\n",
    "    mean_error=[]\n",
    "    std_error=[]\n",
    "    f1 = []\n",
    "    Ci_range = [0.01, 0.1, 1, 5, 10, 25, 50, 100, 1000]\n",
    "    for Ci in Ci_range:\n",
    "        model, prediction = logisticRegression(Xtrain_poly, Xtest_poly, ytrain, ytest, Ci)\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        scores = cross_val_score(model, Xtrain_poly, ytrain, cv=5, scoring='f1')\n",
    "        # f1.append(max(scores))\n",
    "        mean_error.append(np.array(scores).mean())\n",
    "        std_error.append(np.array(scores).std())\n",
    "    \n",
    "    print(Ci_range)\n",
    "    print(mean_error)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rc('font', size=18); plt.rcParams['figure.constrained_layout.use'] = True\n",
    "    plt.errorbar(Ci_range,mean_error,yerr=std_error,linewidth=3)\n",
    "\n",
    "    plt.xlabel('Weight(C)'); plt.ylabel('F1 Score')\n",
    "    # plt.xlim((0,1))\n",
    "    plt.title(\"F1 Score vs C (Poly=2)\")\n",
    "    plt.show()\n",
    "    # return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_CV(X,y):\n",
    "    mean_error=[]\n",
    "    std_error=[]\n",
    "    f1 = []\n",
    "    K_range = [2,3,5,10,30,50,100, 130, 150, 200]\n",
    "    for k in K_range:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        model = KNeighborsClassifier(n_neighbors=k,weights='distance').fit(Xtrain, ytrain)\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        scores = cross_val_score(model, Xtrain, ytrain, cv=5, scoring='f1')\n",
    "        f1.append(max(scores))\n",
    "        mean_error.append(np.array(scores).mean())\n",
    "        std_error.append(np.array(scores).std())\n",
    "    print(K_range)\n",
    "    print(mean_error)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rc('font', size=18); plt.rcParams['figure.constrained_layout.use'] = True\n",
    "    plt.errorbar(K_range,mean_error,yerr=std_error,linewidth=3)\n",
    "    plt.xlabel('k'); plt.ylabel('F1 Score')\n",
    "    # plt.xlim((0,1))\n",
    "    plt.title(\"F1 Score vs k(uniform weight)\")\n",
    "    plt.show()\n",
    "\n",
    "    # return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(X, y, k):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "    Xtrain, Xtest, ytrain, ytest\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier(n_neighbors=k,weights='uniform').fit(Xtrain, ytrain)\n",
    "    prediction = model.predict(Xtest)\n",
    "    return model, prediction, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_Metrics(ytest,prediction):\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    print(\"Confusion matrix (kNN):\")\n",
    "    print(confusion_matrix(ytest,prediction))\n",
    "    print(\"Classification report (kNN):\")\n",
    "    print(classification_report(ytest,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocCurve(model,Xtest_poly, ytest):\n",
    "    # model, prediction = logisticRegression(Xtrain_poly, Xtest_poly, ytrain, ytest, 10)\n",
    "    from sklearn.metrics import roc_curve,auc\n",
    "    fpr, tpr, _ = roc_curve(ytest,model.decision_function(Xtest_poly))\n",
    "    import matplotlib.pyplot as plt\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    plt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_poly, Xtest_poly, ytrain, ytest = splitNaddPoly(X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error=[]\n",
    "std_error=[]\n",
    "f1 = []\n",
    "Ci_range = [0.01, 0.1, 1, 5, 10, 25, 50, 100, 1000]\n",
    "for Ci in Ci_range:\n",
    "    model, prediction = logisticRegression(Xtrain_poly, Xtest_poly, ytrain, ytest, Ci)\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scores = cross_val_score(model, Xtrain_poly, ytrain, cv=5, scoring='roc_auc')\n",
    "    # f1.append(max(scores))\n",
    "    mean_error.append(np.array(scores).mean())\n",
    "    std_error.append(np.array(scores).std())\n",
    "\n",
    "print(Ci_range)\n",
    "print(mean_error)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=18); plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.errorbar(Ci_range,mean_error,yerr=std_error,linewidth=3)\n",
    "\n",
    "plt.xlabel('Weight(C)'); plt.ylabel('roc_auc')\n",
    "# plt.xlim((0,1))\n",
    "plt.title(\"roc_auc vs C (Poly=2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get polynomial and penalty weight value\n",
    "f1_values = errorBar(Xtrain_poly, Xtest_poly, ytrain, ytest)\n",
    "print(f1_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, prediction1 = logisticRegression(Xtrain_poly, Xtest_poly, ytrain, ytest, 0.01)\n",
    "modelResults(ytest, model1, prediction1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyClassifier(Xtrain_poly, Xtest_poly, ytrain, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfpr, Ltpr, Lroc_auc = rocCurve(model1,Xtest_poly, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_CV(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, prediction, Xtest, ytest = kNN(X,y,50)\n",
    "kNN_Metrics(ytest,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocCurve(model,ytest,prediction):\n",
    "    from sklearn.metrics import roc_curve,auc\n",
    "    fpr, tpr, _ = roc_curve(ytest,prediction,)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(fpr,tpr,label='ROC curve_ (area = %0.2f)' % roc_auc)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "kfpr, ktpr, kauc = rocCurve(model,ytest,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinedROC(Lfpr, Ltpr, Lroc_auc, kfpr, ktpr, kauc):  \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(Lfpr, Ltpr,label='LR_ROC (area = %0.2f)' % Lroc_auc)\n",
    "    plt.plot(kfpr, ktpr,label='kNN_ROC (area = %0.2f)' % kauc)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "combinedROC(Lfpr, Ltpr, Lroc_auc, kfpr, ktpr, kauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error=[]\n",
    "std_error=[]\n",
    "f1 = []\n",
    "K_range = [2,3,5,10,30,50,100, 130, 150, 200]\n",
    "for k in K_range:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier(n_neighbors=k,weights='uniform').fit(Xtrain, ytrain)\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scores = cross_val_score(model, Xtrain, ytrain, cv=5, scoring='roc_auc')\n",
    "    f1.append(max(scores))\n",
    "    mean_error.append(np.array(scores).mean())\n",
    "    std_error.append(np.array(scores).std())\n",
    "print(K_range)\n",
    "print(mean_error)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=18); plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.errorbar(K_range,mean_error,yerr=std_error)\n",
    "plt.xlabel('k'); plt.ylabel('roc_auc')\n",
    "# plt.xlim((0,1))\n",
    "plt.title(\"roc_auc vs k(uniform weight)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ae812cea1838cfe625ef2ccd041db9e8a15742a5c13070da45ad927857ccd83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
